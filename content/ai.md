Title:  Game-playing robots, AI, and the Singularity
Date: 2017-6-24
Category: Artificial Intelligence
Status: draft

Wasn't it only yesterday that Gary Kasparov was battling Deep Blue for human supremacy in chess?  It happened 20 years ago.  Today, you can go to Apple's App Store, download Stockfish, and it will easily defeat the average chess grandmaster, possibly even the champion Magnus Carlsen (to beat him with utter certainty you may need to run Stockfish on your desktop PC...).  

Of course, once AI accomplishes such a feat, people somehow realize chess wasn't that great a test of intelligence after all.  Obviously, we need to pick a more creative pursuit, like Go.  

In 2015, the best Go-playing program could not even beat a top amateur.  Go seemed safe from AI for at least a decade.  Then in 2016, Google Deepmind unveiled AlphaGo, a Go-playing engine relying upon deep learning (neural networks with more than several layers of neurons).  

AlphaGo had been trained on all available games and had furthermore been playing versions of itself.  You could consider that on an evolutionary timescale, AlphaGo had been playing a million times? longer than any human could.  

AlphaGo easily beat the Go world champion, Lee Sedol.  An updated version a year later easily crushed everyone it faced, including the number one player in the world.  

Has the age of AI finally arrived?  Elon Musk thinks so.  He is starting a company to develop neural implants -- the only hope to fight intelligent machines is by augmenting our intelligence.  Google has re-branded itself as an AI company.  Only a few years before, it had re-branded itself as a mobile app company.  

It's worth considering that in the 1950s, it was thought that within a decade, every household would have a humanoid robot servant.  The history of AI has seen surges of optimism (and funding) followed by "winters" of pessimism (and little funding).  

It may be than in the next several years we will decide AlphaGo proves nothing.  The fact that Google algorithms can easily recognize cats in YouTube vidoes proves nothing.  That cars can drive themselves proves nothing.  Etc.  Do any of these things give strong evidence as to cracking the problem of general intelligence?   

The new approach to AI involves *deep learning*.  Like other techniques from the field of machine learning, it involves learning parameter values by fitting a model to training data.  The model is not based on "understanding" what a human might understand from the data.  Instead it uses statistical relationships in the data to drive the parameters to values that are most likely to be predictive on new data.

We are in a funny situation where our best learning algorithms are learning in a way which is completely opaque to us.  If we do end up buiding intelligent machines, we may very well have no idea how they work.  This would not bother them of course (presumably).  They will then presumably seek to improve themselves and generate more intelligent machines.  After a handful of iterations, our intelligence compared to theirs may be like that of a bug to us.

Nick Bostrom, Super Intelligence.





