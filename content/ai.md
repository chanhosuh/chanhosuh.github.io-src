Title:  Game-playing robots, AI, and the Singularity
Date: 2017-6-24
Category: Artificial Intelligence, Singularity, history, philosophy
Status: draft

It may be hard to imagine for those that grew up during the iPhone era, but over 20 years ago, the world was shocked when the human chess champion, Gary Kasparov, was defeated by a computer, IBM's Deep Blue, marking the end of human supremacy in chess.  Today, you can go to the Apple App Store, download Stockfish, and it will easily defeat a chess grandmaster, or even the champion Magnus Carlsen (marginally less easily).

In hindsight, chess was too easy a test for computers.  Using that as a benchmark of machine intelligence was unwise.  No fundamental insight into intelligence was required, just purely technical research into extending computing power into the realm of tree searches.

Obviously we need to pick something needing true human creativity.  Like Go (also known as baduk or weiqi). 

In 2015, the best Go-playing program could not even beat a top amateur.  Go seemed safe from AI for at least a decade.  Then in 2016, Google Deepmind unveiled AlphaGo, a Go-playing engine relying upon deep learning (neural networks with more than several layers of neurons).  

AlphaGo had been trained on all available games and had furthermore been playing versions of itself.  You could consider that on an evolutionary timescale, AlphaGo had been playing a million times? longer than any human could.  

AlphaGo easily beat the Go world champion, Lee Sedol.  An updated version a year later easily crushed everyone it faced, including the number one player in the world.  

Has the age of AI finally arrived?  Elon Musk thinks so.  He is starting a company to develop neural implants -- the only hope to fight intelligent machines is by augmenting our intelligence.  Google has re-branded itself as an AI company.  Only a few years before, it had re-branded itself as a mobile app company.  

It's worth considering that in the 1950s, it was thought that within a decade, every household would have a humanoid robot servant.  The history of AI has seen surges of optimism (and funding) followed by "winters" of pessimism (and little funding).  

It may be than in the next several years we will decide AlphaGo proves nothing.  The fact that Google algorithms can easily recognize cats in YouTube vidoes proves nothing.  That cars can drive themselves proves nothing.  Etc.  Do any of these things give strong evidence as to cracking the problem of general intelligence?   

The new approach to AI involves *deep learning*.  Like other techniques from the field of machine learning, it involves learning parameter values by fitting a model to training data.  The model is not based on "understanding" what a human might understand from the data.  Instead it uses statistical relationships in the data to drive the parameters to values that are most likely to be predictive on new data.

We are in a funny situation where our best learning algorithms are learning in a way which is completely opaque to us.  If we do end up buiding intelligent machines, we may very well have no idea how they work.  This would not bother them of course (presumably).  They will then presumably seek to improve themselves and generate more intelligent machines.  After a handful of iterations, our intelligence compared to theirs may be like that of a bug to us.

Nick Bostrom, Super Intelligence.





